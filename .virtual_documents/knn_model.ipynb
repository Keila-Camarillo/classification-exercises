import warnings
warnings.filterwarnings("ignore")

# Tabular data friends:
import pandas as pd
import numpy as np

# Data viz:
import matplotlib.pyplot as plt
import seaborn as sns

# Sklearn stuff:
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix

# Data acquisition
from pydataset import data

import prepare as prep
import modeling as mod


train, validate, test = prep.get_prep_split_titanic()


train
col= ["passenger_id", "sex", "survived", "embarked"]


x_train, y_train, x_validate, y_validate, x_test, y_test = mod.create_x_y(train, validate, test, "survived", col )


x_train


knn5 = KNeighborsClassifier(n_neighbors=5, weights='uniform')
knn5.fit(x_train, y_train)


y_pred5 = knn5.predict(x_train)
y_pred_proba5 = knn5.predict_proba(x_train)
# y_pred_proba5 = knn5.predict_proba(x_train)


y_pred_proba5[:5]



confusion_matrix(y_train, y_pred5)


pd.crosstab(y_train, y_pred5)


print(classification_report(y_train, y_pred5))


def knn_model_accuracies(x_train, y_train, x_validate, y_validate):
    '''
    This function is an aid for KNN models.
    Takes arguments x_train, y_train, x_validate, y_validate, which iterates through 10 n_neighbors and fits 
    and then produces a dataframe that shows the train score, validation score and their differences
    '''
    model_accuracies = {}

    for i in range(1,21):
        #MAKE THE THING
        knn = KNeighborsClassifier(n_neighbors=i)

        #FIT THE THING
        knn.fit(x_train, y_train)

        #USE THE THING
        model_accuracies[f'{i}_neighbors'] = {
            'train_score': round(knn.score(x_train, y_train),2),
            'validate_score':round(knn.score(x_validate, y_validate),2),
            'diff_score': round(round(knn.score(x_train, y_train),2) - round(knn.score(x_validate, y_validate),2), 2)
        }
    return pd.DataFrame(model_accuracies).T



knn_model_accuracies(x_train, y_train, x_validate, y_validate)


knn4 = KNeighborsClassifier(n_neighbors=4)


knn4.fit(x_train, y_train)


print(f"""Accuracy of KNN (k=8) classifier on validate set: {knn8.score(x_validate, y_validate):.2f}
     
Accuracy of KNN (k=5) classifier on validate set: {knn5.score(x_validate, y_validate):.2f}""")


print(classification_report(y_train, y_pred5))


#VIZ
def knn_viz_20(x_train, y_train, x_validate, y_validate):
    '''
    This function helps visualize your knn results by fitting the given arguments (x_train, y_train, x_validate, y_validate)
    and using these features with the KNeighborsClassifier to calculate through an iteration of 20 and find a train score and validation score and producing the vsual plot
    '''
    metrics = []

    for k in range(1,21):

        # MAKE the thing
        knn = KNeighborsClassifier(n_neighbors=k)

        # FIT the thing (remember only fit on training data)
        knn.fit(x_train, y_train)

        # USE the thing (calculate accuracy)
        train_score = knn.score(x_train, y_train)
        validate_score = knn.score(x_validate, y_validate)

        output = {
            "k": k,
            "train_score": train_score,
            "validate_score": validate_score
        }

        metrics.append(output)

    #conver to df
    results = pd.DataFrame(metrics)

    # plot the data
    results.set_index('k').plot(figsize = (16,9))
    plt.ylabel('Accuracy')
    plt.xticks(np.arange(0,21,1))
    plt.grid()


mod.knn_viz_20(x_train, y_train, x_validate, y_validate)
